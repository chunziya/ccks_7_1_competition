{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding : utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from jieba.analyse import *\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "import keras.backend as K\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "# 创建一个logger\n",
    "file_path = 'log/'\n",
    "logger = logging.getLogger('mylogger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# 创建一个handler\n",
    "timestamp = time.strftime(\"%Y.%m.%d_%H.%M.%S\", time.localtime())\n",
    "fh = logging.FileHandler(file_path + 'log_' + timestamp +'.txt')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "# 再创建一个handler，用于输出到控制台\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "# 定义handler的输出格式\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s] ## %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "# 给logger添加handler\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "# set some global params\n",
    "learning_rate = 5e-5\n",
    "min_learning_rate = 1e-5\n",
    "config_path = '../bert_base/bert_pretrained_model/chinese_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = '../bert_base/bert_pretrained_model/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = '../bert_base/bert_pretrained_model/chinese_L-12_H-768_A-12/vocab.txt'\n",
    "MAX_LEN = 150\n",
    "foldnum = 5\n",
    "BATCHSIZE = 8\n",
    "n_class = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    2550\n",
       "3    1266\n",
       "5     866\n",
       "2     144\n",
       "0     100\n",
       "6      52\n",
       "4      10\n",
       "1       4\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv', delimiter=\"\\t\")\n",
    "label_map = {\"NoneType\":0,\"医学专科\":1,\"检查科目\":2,\"疾病\":3,\"病毒\":4,\"症状\":5,\"细菌\":6,\"药物\":7}\n",
    "train_data['Type'] = train_data['Type'].apply(lambda x:label_map[x])\n",
    "train_data['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 4992\n",
      "test data: 2974\n",
      "A医学百科替加氟胶囊条目介绍替加氟胶囊的功效作用，替加氟胶囊的副作用和服用方法等。替加氟胶囊（TegafurCapsules），主要治疗消化道肿瘤，对胃癌、结肠癌、直肠癌有一定疗效。也可用于替加氟胶囊替加氟胶囊，成都通德药业有限公司生产制造，可用于膀胱癌前列腺癌肾癌等。替加氟胶囊，适应症为抗肿瘤药。适用于消化道肿瘤，如胃癌、结肠癌和胰腺癌，也可用于乳腺癌、支气管肺癌和原发性肝癌等。\n",
      "[0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 创建分词器\n",
    "token_dict = {}\n",
    "with open(dict_path, 'r', encoding='utf-8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "tokenizer = Tokenizer(token_dict)\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    r='[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{}~]+'\n",
    "    text = re.sub(r, \"\", text)       # 去除标点\n",
    "    text = text.replace(\"本词条内容尚未完善，欢迎各位编辑词条，贡献自己的专业知识！\", \"\")       # 去除无意义的词语\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # 合并正文中过多的空格\n",
    "    return text.strip()\n",
    "    \n",
    "\n",
    "# 读取数据集\n",
    "label_map = {\"NoneType\":0,\"医学专科\":1,\"检查科目\":2,\"疾病\":3,\"病毒\":4,\"症状\":5,\"细菌\":6,\"药物\":7}\n",
    "train_df = pd.read_csv('data/train_data.csv', delimiter=\"\\t\")\n",
    "train_df['Type'] = train_df['Type'].apply(lambda x:label_map[x])\n",
    "print(\"train data: \" + str(len(train_df)))\n",
    "test_df = pd.read_csv('data/test_data.csv', delimiter=\"\\t\")\n",
    "print(\"test data: \" + str(len(test_df)))\n",
    "\n",
    "# 缺失值处理\n",
    "train_df[\"Descreption\"] = train_df[\"Descreption\"].fillna('')\n",
    "test_df[\"Descreption\"] = test_df[\"Descreption\"].fillna('')\n",
    "\n",
    "# 数据清洗\n",
    "train_df[\"Descreption\"] = train_df[\"Descreption\"].apply(clean)\n",
    "test_df[\"Descreption\"] = test_df[\"Descreption\"].apply(clean)\n",
    "\n",
    "# 特征\n",
    "train_fea = train_df['Descreption'].values\n",
    "test_fea = test_df['Descreption'].values\n",
    "print(train_fea[0])\n",
    "\n",
    "# 类标\n",
    "labels = train_df['Type']  # 数字\n",
    "labels_cat = to_categorical(labels)  # 数组\n",
    "labels_cat = labels_cat.astype(np.int32)\n",
    "print(labels_cat[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator for generating bathc data for traning\n",
    "class data_generator:\n",
    "    def __init__(self, data, batch_size=BATCHSIZE):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = len(self.data[0]) // self.batch_size\n",
    "        if len(self.data[0]) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            X, y = self.data\n",
    "            idxs = list(range(len(self.data[0])))\n",
    "            np.random.shuffle(idxs)\n",
    "            T, T_, Y = [], [], []\n",
    "            for c, i in enumerate(idxs):\n",
    "                text = X[i]\n",
    "                t, t_ = tokenizer.encode(first=text, max_len = MAX_LEN)\n",
    "                T.append(t)\n",
    "                T_.append(t_)\n",
    "                Y.append(y[i])\n",
    "                if len(T) == self.batch_size or i == idxs[-1]:\n",
    "                    T = np.array(T)\n",
    "                    T_ = np.array(T_)\n",
    "                    # T = sequence.pad_sequences(T, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "                    # T_ = sequence.pad_sequences(T_, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "                    Y = np.array(Y)\n",
    "                    yield [T, T_], Y\n",
    "                    T, T_, Y = [], [], []\n",
    "                    \n",
    "                    \n",
    "def get_model():\n",
    "    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path)\n",
    "    for l in bert_model.layers:\n",
    "        l.trainable = True\n",
    "\n",
    "    T1 = Input(shape=(None,))\n",
    "    T2 = Input(shape=(None,))\n",
    "\n",
    "    T = bert_model([T1, T2])\n",
    "\n",
    "    T = Lambda(lambda x: x[:, 0])(T)\n",
    "    T = Dropout(0.5)(T)\n",
    "    T = Dropout(0.5)(T)\n",
    "    # t3 = Dropout(0.5)(T)\n",
    "    # t4 = Dropout(0.5)(T)\n",
    "    # t5 = Dropout(0.5)(T)\n",
    "    # merged = concatenate([t1,t2,t3,t4,t5])\n",
    "    # outputmerged = Dense(8, activation='relu')(merged)\n",
    "    output = Dense(n_class, activation='softmax')(T)\n",
    "\n",
    "    model = Model([T1, T2], output)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "class Evaluate(Callback):\n",
    "\n",
    "    def __init__(self, val_data, val_index):\n",
    "        self.score = []\n",
    "        self.best = 0.\n",
    "        self.early_stopping = 0\n",
    "        self.val_data = val_data\n",
    "        self.val_index = val_index\n",
    "        self.predict = []\n",
    "        self.lr = 0\n",
    "        self.passed = 0\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"第一个epoch用来warmup，第二个epoch把学习率降到最低\n",
    "        \"\"\"\n",
    "        if self.passed < self.params['steps']:\n",
    "            self.lr = (self.passed + 1.) / self.params['steps'] * learning_rate\n",
    "            K.set_value(self.model.optimizer.lr, self.lr)\n",
    "            self.passed += 1\n",
    "        elif self.params['steps'] <= self.passed < self.params['steps'] * 2:\n",
    "            self.lr = (2 - (self.passed + 1.) / self.params['steps']) * (learning_rate - min_learning_rate)\n",
    "            self.lr += min_learning_rate\n",
    "            K.set_value(self.model.optimizer.lr, self.lr)\n",
    "            self.passed += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        score, acc, f1 = self.evaluate()\n",
    "        if score > self.best:\n",
    "            self.best = score\n",
    "            self.early_stopping = 0\n",
    "            model.save_weights('model_save_1/bert{}.w'.format(fold))\n",
    "        else:\n",
    "            self.early_stopping += 1\n",
    "        logger.info('lr: %.6f, epoch: %d, score: %.4f, acc: %.4f, f1: %.4f,best: %.4f\\n' % (self.lr, epoch, score, acc, f1, self.best))\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.predict = []\n",
    "        prob = []\n",
    "        val_x, val_y, val_cat = self.val_data\n",
    "        for i in tqdm(range(len(val_x))):\n",
    "            test = val_x[i]\n",
    "\n",
    "            t1, t1_ = tokenizer.encode(first=test, max_len=MAX_LEN)\n",
    "            T1, T1_ = np.array([t1]), np.array([t1_])\n",
    "            # T1 = sequence.pad_sequences([t1], maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "            # T1_ = sequence.pad_sequences([t1_], maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "            _prob = model.predict([T1, T1_])\n",
    "            oof_train[self.val_index[i]] = _prob[0]\n",
    "            self.predict.append(np.argmax(_prob, axis=1)[0]+1)\n",
    "            prob.append(_prob[0])\n",
    "\n",
    "        score = 1.0 / (1 + mean_absolute_error(val_y+1, self.predict))\n",
    "        acc = accuracy_score(val_y+1, self.predict)\n",
    "        f1 = f1_score(val_y+1, self.predict, average='macro')\n",
    "        return score, acc, f1\n",
    "\n",
    "\n",
    "def predict(data):\n",
    "    prob = []\n",
    "    val_x = data\n",
    "    for i in tqdm(range(len(val_x))):\n",
    "        text = val_x[i]\n",
    "        t1, t1_ = tokenizer.encode(first=text, max_len=MAX_LEN)\n",
    "        T1, T1_ = np.array([t1]), np.array([t1_])\n",
    "        # T1 = sequence.pad_sequences([t1], maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "        # T1_ = sequence.pad_sequences([t1_], maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "        _prob = model.predict([T1, T1_])\n",
    "        prob.append(_prob[0])\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-06-05 16:59:11,281][INFO] ## ================     fold 0        ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            6152        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 101,683,208\n",
      "Trainable params: 101,683,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py3.7_tf1.14_torch1.4/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 99s 199ms/step - loss: 0.6857 - acc: 0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:20<00:00, 47.85it/s]\n",
      "[2020-06-05 17:02:07,156][INFO] ## lr: 0.000050, epoch: 0, score: 0.8215, acc: 0.9510, f1: 0.6112,best: 0.8215\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "500/500 [==============================] - 80s 160ms/step - loss: 0.2224 - acc: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:19<00:00, 51.97it/s]\n",
      "[2020-06-05 17:03:49,555][INFO] ## lr: 0.000010, epoch: 1, score: 0.8920, acc: 0.9670, f1: 0.7383,best: 0.8920\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "500/500 [==============================] - 77s 155ms/step - loss: 0.1209 - acc: 0.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:19<00:00, 52.21it/s]\n",
      "[2020-06-05 17:05:29,573][INFO] ## lr: 0.000010, epoch: 2, score: 0.8936, acc: 0.9690, f1: 0.7641,best: 0.8936\n",
      "\n",
      "100%|██████████| 2974/2974 [00:54<00:00, 54.96it/s]\n",
      "[2020-06-05 17:06:26,438][INFO] ## ================     fold 1        ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            6152        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 101,683,208\n",
      "Trainable params: 101,683,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.6385 - acc: 0.8357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:21<00:00, 45.47it/s]\n",
      "[2020-06-05 17:09:16,715][INFO] ## lr: 0.000050, epoch: 0, score: 0.5453, acc: 0.8128, f1: 0.5699,best: 0.5453\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "500/500 [==============================] - 80s 161ms/step - loss: 0.2350 - acc: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:18<00:00, 55.19it/s]\n",
      "[2020-06-05 17:10:58,543][INFO] ## lr: 0.000010, epoch: 1, score: 0.9074, acc: 0.9650, f1: 0.7760,best: 0.9074\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "500/500 [==============================] - 77s 154ms/step - loss: 0.1081 - acc: 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:19<00:00, 52.38it/s]\n",
      "[2020-06-05 17:12:38,806][INFO] ## lr: 0.000010, epoch: 2, score: 0.9182, acc: 0.9680, f1: 0.9557,best: 0.9182\n",
      "\n",
      "100%|██████████| 2974/2974 [00:53<00:00, 55.19it/s]\n",
      "[2020-06-05 17:13:34,774][INFO] ## ================     fold 2        ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            6152        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 101,683,208\n",
      "Trainable params: 101,683,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.6771 - acc: 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:24<00:00, 41.27it/s]\n",
      "[2020-06-05 17:16:23,731][INFO] ## lr: 0.000050, epoch: 0, score: 0.9173, acc: 0.9689, f1: 0.7979,best: 0.9173\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "500/500 [==============================] - 80s 160ms/step - loss: 0.1945 - acc: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:20<00:00, 48.38it/s]\n",
      "[2020-06-05 17:18:07,525][INFO] ## lr: 0.000010, epoch: 1, score: 0.9258, acc: 0.9749, f1: 0.8959,best: 0.9258\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "500/500 [==============================] - 77s 155ms/step - loss: 0.0983 - acc: 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:21<00:00, 46.38it/s]\n",
      "[2020-06-05 17:19:49,823][INFO] ## lr: 0.000010, epoch: 2, score: 0.9318, acc: 0.9749, f1: 0.9105,best: 0.9318\n",
      "\n",
      "100%|██████████| 2974/2974 [00:59<00:00, 49.59it/s]\n",
      "[2020-06-05 17:20:51,692][INFO] ## ================     fold 3        ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            6152        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 101,683,208\n",
      "Trainable params: 101,683,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 95s 191ms/step - loss: 0.6077 - acc: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:22<00:00, 44.80it/s]\n",
      "[2020-06-05 17:23:38,746][INFO] ## lr: 0.000050, epoch: 0, score: 0.8537, acc: 0.9469, f1: 0.6416,best: 0.8537\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "500/500 [==============================] - 81s 161ms/step - loss: 0.2124 - acc: 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:20<00:00, 48.11it/s]\n",
      "[2020-06-05 17:25:23,511][INFO] ## lr: 0.000010, epoch: 1, score: 0.9064, acc: 0.9619, f1: 0.8303,best: 0.9064\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "500/500 [==============================] - 78s 156ms/step - loss: 0.0862 - acc: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:20<00:00, 48.47it/s]\n",
      "[2020-06-05 17:27:05,124][INFO] ## lr: 0.000010, epoch: 2, score: 0.9241, acc: 0.9679, f1: 0.8422,best: 0.9241\n",
      "\n",
      "100%|██████████| 2974/2974 [01:01<00:00, 48.21it/s]\n",
      "[2020-06-05 17:28:08,515][INFO] ## ================     fold 4        ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 768)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            6152        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 101,683,208\n",
      "Trainable params: 101,683,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 96s 193ms/step - loss: 0.6040 - acc: 0.8372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:23<00:00, 42.85it/s]\n",
      "[2020-06-05 17:31:01,220][INFO] ## lr: 0.000050, epoch: 0, score: 0.8762, acc: 0.9509, f1: 0.5481,best: 0.8762\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "500/500 [==============================] - 81s 162ms/step - loss: 0.2079 - acc: 0.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:19<00:00, 52.22it/s]\n",
      "[2020-06-05 17:32:44,682][INFO] ## lr: 0.000010, epoch: 1, score: 0.9258, acc: 0.9719, f1: 0.7693,best: 0.9258\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "500/500 [==============================] - 78s 156ms/step - loss: 0.1000 - acc: 0.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [00:19<00:00, 51.55it/s]\n",
      "[2020-06-05 17:34:22,121][INFO] ## lr: 0.000010, epoch: 2, score: 0.9106, acc: 0.9629, f1: 0.8255,best: 0.9258\n",
      "\n",
      "100%|██████████| 2974/2974 [00:56<00:00, 52.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "skf = StratifiedKFold(n_splits=foldnum, shuffle=True, random_state=42)\n",
    "\n",
    "oof_train = np.zeros((len(train_df), n_class), dtype=np.float32)\n",
    "oof_test = np.zeros((len(test_df), n_class), dtype=np.float32)\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(train_fea, labels)):\n",
    "    logger.info('================     fold {}        ==============='.format(fold))\n",
    "    x = train_fea[train_index]\n",
    "    y = labels_cat[train_index]\n",
    "\n",
    "    val_x = train_fea[valid_index]\n",
    "    val_y = labels[valid_index]\n",
    "    val_cat = labels_cat[valid_index]\n",
    "\n",
    "    train_D = data_generator([x, y])\n",
    "    evaluator = Evaluate([val_x, val_y, val_cat], valid_index)\n",
    "    model = get_model()\n",
    "    # if os.path.exists('./model_save/bert{}.w'.format(fold)):\n",
    "    #     model.load_weights('./model_save/bert{}.w'.format(fold))\n",
    "    #model = ParallelModel(model, 2)\n",
    "    model.fit_generator(train_D.__iter__(),\n",
    "                        steps_per_epoch=len(train_D),\n",
    "                        epochs=3,\n",
    "                        callbacks=[evaluator]\n",
    "                       )\n",
    "    model.load_weights('model_save_1/bert{}.w'.format(fold))\n",
    "    oof_test += predict(test_fea)\n",
    "    K.clear_session()\n",
    "    oof_test /= foldnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154593801577113\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('model_save_1/train_bert.txt', oof_train)\n",
    "np.savetxt('model_save_1/test_bert.txt', oof_test)\n",
    "\n",
    "cv_score = 1.0 / (1 + mean_absolute_error(labels+1, np.argmax(oof_train, axis=1) + 1))\n",
    "print(cv_score)\n",
    "\n",
    "label_map = {0:\"NoneType\",1:\"医学专科\",2:\"检查科目\",3:\"疾病\",4:\"病毒\",5:\"症状\",6:\"细菌\",7:\"药物\"}\n",
    "test_df['Type'] = np.argmax(oof_test, axis=1)\n",
    "test_df['Type'] = test_df['Type'].apply(lambda x: label_map[x])\n",
    "test_df[['Name', 'Type']].to_csv('submit/baseline_1_{}.txt'.format(cv_score), sep='\\t', header=None, index=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.7_tf1.14_torch1.4]",
   "language": "python",
   "name": "conda-env-py3.7_tf1.14_torch1.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
